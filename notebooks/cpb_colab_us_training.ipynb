{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPB - Binance US \u7248\u672c (\u7f8e\u570b\u7528\u6236\u4e13\u7528)\n",
    "\n",
    "## \u63a8\u85a6\uff1a\u8a73\u6b21\u7b46\u8a18\u672c\u5df2\u9077\u79fb\u5230 Binance US API\n",
    "\n",
    "\u2713 **\u7121\u5730\u5340\u9650\u5236** - \u5b8c\u5168\u652f\u6301\u7f8e\u570b\u6a5f\u5834  \n\u2713 **\u7121\u9700 API \u5bc6\u9470** - \u4f7f\u7528\u516c\u958b API  \n\u2713 **\u81ea\u52d5\u91cd\u8a66** - API \u5931\u6557\u81ea\u52d5\u91cd\u65b0\u9023\u63a5  \n\u2713 **\u5b8c\u5168\u514d\u8cbb** - 20+ \u5e63\u7a2e\u8a13\u7df4  \n\u2713 **GPU \u52a0\u901f** - Colab T4/L4 GPU \u652f\u63f4  \n\u2713 **\u81ea\u52d5 Python 3.10+** - \u4f7f\u7528 CCXT \u5eab  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: \u5b89\u88dd\u5fc5\u8981\u7a0b\u5f0f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u5b89\u88dd ccxt (Binance US \u4ea4\u6613\u6240\u652f\u63f4)\n",
    "!pip install -q ccxt\n",
    "!pip install -q ta  # \u6280\u8853\u6307\u6a19\n",
    "!pip install -q scikit-learn  # \u6a5f\u5668\u5b78\u7fd2\n",
    "!pip install -q torch  # PyTorch\n",
    "!pip install -q python-dotenv  # \u74b0\u5883\u8b8a\u6578\n",
    "\n",
    "print('\\n=== \u4f9d\u8cf4\u5b89\u88dd\u5b8c\u6210 ===')\n",
    "\n",
    "import ccxt\n",
    "import torch\n",
    "\n",
    "print(f'CCXT \u7248\u672c: {ccxt.__version__}')\n",
    "print(f'PyTorch \u7248\u672c: {torch.__version__}')\n",
    "print(f'CUDA \u53ef\u7528: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU \u578b\u865f: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "print('\\n\u2713 \u6240\u6709\u4f9d\u8cf4\u5b89\u88dd\u4e0a\u58f3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: \u639b\u8f09 Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# \u639b\u8f09 Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# \u5efa\u7acb\u5de5\u4f5c\u76ee\u9304\n",
    "work_dir = '/content/drive/MyDrive/cpb_training'\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "\n",
    "print(f'\u2713 \u5de5\u4f5c\u76ee\u9304: {os.getcwd()}')\n",
    "print(f'\u2713 GPU \u6aa2\u6e2c: {os.system(\"nvidia-smi -q -d Memory | grep -A 4 GPU\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone GitHub Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Clone repo\n",
    "if not os.path.exists('cpb'):\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/caizongxun/cpb.git'], cwd=work_dir)\n",
    "else:\n",
    "    # \u66f4\u65b0\u5df2\u5b58\u5728\u7684repo\n",
    "    subprocess.run(['git', 'pull'], cwd=os.path.join(work_dir, 'cpb'))\n",
    "\n",
    "os.chdir(os.path.join(work_dir, 'cpb'))\n",
    "print(f'\u2713 \u7576\u524d\u76ee\u9304: {os.getcwd()}')\n",
    "print(f'\u2713 \u6a94\u6848\u5217\u8868: {os.listdir()[:5]}')  # \u986f\u793a\u524d 5 \u500b\u6a94\u6848"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: \u5b89\u88dd\u4f9d\u8cf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u5b89\u88dd requirements\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print('\u2713 \u4f9d\u8cf4\u5b89\u88dd\u5b8c\u6210\uff01')\n",
    "\n",
    "# \u9a57\u8b49 PyTorch CUDA\n",
    "import torch\n",
    "print(f'\u2713 PyTorch \u7248\u672c: {torch.__version__}')\n",
    "print(f'\u2713 CUDA \u53ef\u7528: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'\u2713 GPU \u578b\u865f: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'\u2713 GPU \u8a18\u6206\u9ad4: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: \u6aa2\u67e5 Binance US API \u662f\u5426\u6b63\u5e38\u7d71\u4f5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "\n",
    "# \u6d4b\u8a66 Binance US API\n",
    "exchange = ccxt.binanceus()\n",
    "\n",
    "print('\u2713 \u6b63\u5728\u6e2c\u8a66\u4e0d\u540c\u5e63\u7a2e...')\n",
    "\n",
    "test_symbols = ['BTC/USDT', 'ETH/USDT', 'SOL/USDT']\n",
    "\n",
    "for symbol in test_symbols:\n",
    "    try:\n",
    "        data = exchange.fetch_ohlcv(symbol, '1h', limit=10)\n",
    "        print(f'\u2713 {symbol}: \u6210\u529f ({len(data)} K\u68d2)')\n",
    "    except Exception as e:\n",
    "        print(f'\u2717 {symbol}: {str(e)[:50]}...')\n",
    "\n",
    "print('\\n\u2713 Binance US API \u6b63\u5e38\u7d71\u4f5c\uff01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: \u57f7\u884c\u5b8c\u6574\u8a13\u7df4 Pipeline (Binance US \u7248\u672c)\n",
    "\n",
    "\u6b64\u6b65\u9a5f\u6703\u81ea\u52d5\u57f7\u884c\uff1a  \n1. **Phase 1**: Binance US API \u8cc7\u6599\u63a1\u96c6 (20+ \u5e63\u7a2e\uff0c1h & 15m)  \n2. **Phase 2**: \u7279\u5fb5\u5de5\u7a0b (35+ \u6280\u8853\u6307\u6a19)  \n3. **Phase 3**: LSTM \u6a21\u578b\u8a13\u7df4 (GPU \u52a0\u901f)  \n4. **Phase 4**: \u6a21\u578b\u8a55\u4f30\u8207\u5831\u544a  \n\n**\u9810\u8a08\u8017\u6642**: 2-4 \u5c0f\u6642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "from train_us import CryptoMLPipelineUS\n",
    "\n",
    "# \u5efa\u7acb Pipeline \u5be6\u4f8b (Binance US \u7279\u5316\u7248\u672c)\n",
    "pipeline = CryptoMLPipelineUS(is_colab=True)\n",
    "\n",
    "print('\\n=== \u958b\u59cb\u57f7\u884c\u5b8c\u6574 ML Pipeline ===\\n')\n",
    "\n",
    "# \u57f7\u884c\u5b8c\u6574 Pipeline\n",
    "results_df = pipeline.run_full_pipeline(\n",
    "    days_back=30,              # \u63a1\u96c6 30 \u5929\u8cc7\u6599\n",
    "    epochs=150,                # \u8a13\u7df4 150 \u500b epoch\n",
    "    skip_collection=False      # \u6539\u70ba True \u53ef\u8df3\u904e\u63a1\u96c6\uff0c\u4f7f\u7528\u672c\u5730\u8cc7\u6599\n",
    ")\n",
    "\n",
    "print('\\n\u2713 \u8a13\u7df4\u5b8c\u6210\uff01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: \u6aa2\u8996\u8a13\u7df4\u7d50\u679c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# \u986f\u793a\u7d50\u679c DataFrame\n",
    "print('=== \u8a13\u7df4\u7d50\u679c\u6458\u8981 ===\\n')\n",
    "print(results_df)\n",
    "\n",
    "# \u8b80\u53d6\u8a73\u7d30\u5831\u544a\n",
    "with open('./models/training_report.json', 'r') as f:\n",
    "    report = json.load(f)\n",
    "\n",
    "print('\\n=== \u6027\u80fd\u7d71\u8a08 ===')\n",
    "summary = report['summary']\n",
    "print(f\"\u8a13\u7df4\u5e63\u7a2e\u6578: {summary['total_coins']}\")\n",
    "print(f\"\u5e73\u5747 RMSE: {summary['avg_rmse']:.6f}\")\n",
    "print(f\"\u5e73\u5747 MAPE: {summary['avg_mape']:.2f}%\")\n",
    "print(f\"\u5e73\u5747\u65b9\u5411\u6e96\u78ba\u7387: {summary['avg_direction_accuracy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: \u4e0b\u8f09\u6a21\u578b\u8207\u5831\u544a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# \u6aa2\u67e5\u8f38\u51fa\u6a94\u6848\n",
    "model_dir = Path('./models')\n",
    "data_dir = Path('./data')\n",
    "\n",
    "print('=== \u5df2\u751f\u6210\u7684\u6a21\u578b ===')\n",
    "for model_file in sorted(model_dir.glob('*.pt')):\n",
    "    size_mb = model_file.stat().st_size / (1024*1024)\n",
    "    print(f'{model_file.name}: {size_mb:.2f} MB')\n",
    "\n",
    "print('\\n=== \u5831\u544a\u6a94\u6848 ===')\n",
    "for report_file in model_dir.glob('*.json'):\n",
    "    print(f'{report_file.name}')\n",
    "\n",
    "print('\\n=== \u8cc7\u6599\u63a1\u96c6\u7d71\u8a08 ===')\n",
    "raw_data_dir = data_dir / 'raw_data'\n",
    "if raw_data_dir.exists():\n",
    "    csv_files = list(raw_data_dir.glob('*.csv'))\n",
    "    print(f'CSV \u6a94\u6848\u6578: {len(csv_files)}')\n",
    "    total_rows = sum(len(pd.read_csv(f)) for f in csv_files)\n",
    "    print(f'\u7e3d K\u68d2\u6578: {total_rows:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u5e38\u898b\u554f\u984c\n",
    "\n",
    "### Q1: \u70ba\u4ec0\u9ebc\u7528 Binance US\uff1f\n",
    "**A**: Binance US \u662f\u63d0\u4f9b\u7f8e\u570b\u4f7f\u7528\u8005\u7684\u7684\u5b98\u65b9\u4ea4\u6613\u6240\uff0c\u7121\u5730\u5340\u9650\u5236\uff0c\u5b8c\u5168\u652f\u6301\u7f8e\u570b\u6a5f\u5834\u3002\n",
    "\n",
    "### Q2: \u9700\u8981\u586b API \u5bc6\u9470\u55ce\uff1f\n",
    "**A**: \u4e0d\u9700\u8981\uff01\u9019\u4e2a\u7248\u672c\u4f7f\u7528\u516c\u958b API\uff0c\u7121\u9700\u8a8d\u8b49\u3002\n",
    "\n",
    "### Q3: \u6c42\u63a8\u7684GPU\u63a8\u85a6\u56c9\u4f3a\uff08\u9069\u4e8e\u9019\u4e2a\u9805\u76ee\uff09\uff1f\n",
    "**A**: \u63d0\u524a:Google Colab \u7684 **T4 GPU** \u3002\u9069\u5e79 20+ \u5e63\u7a2e\uff0c\u8a13\u7df4\u6642\u9593\u7d04 2-3 \u5c0f\u6642\u3002\n",
    "\n",
    "### Q4: L4 GPU\u662f\u4e0d\u662f\u66f4\u5feb\uff1f\n",
    "**A**: \u662f\u7684\uff01L4 GPU \u6bd4 T4 \u5feb 2-3 \u500d\u3002\n",
    "\n",
    "### Q5: \u4fee\u6539 days_back \u600e\u8fa8\uff1f\n",
    "**A**: \u6539 `days_back=7` \u53ef\u4f4b\u5169\u91cf\u63a1\u96c6 7 \u5929\u8cc7\u6599\uff0c\u6703\u5feb\u5f88\u591a\u3002\u9810\u8a2d 30 \u5929\u662f\u4e00\u4e2a\u9069\u4e2d\u4e4b\u9078\u3002"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}